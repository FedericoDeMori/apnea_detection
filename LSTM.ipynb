{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning and Data Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Data Loading\n",
    "import wfdb\n",
    "\n",
    "# IPython utilities for better display\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load and process the data\n",
    "\n",
    "def process_patient_data(patient_id, data_dir):\n",
    "    file_name = f'/{patient_id}'\n",
    "\n",
    "    # Load patient data\n",
    "    record = wfdb.rdheader(data_dir + file_name)\n",
    "    signals, fields = wfdb.rdsamp(data_dir + file_name)\n",
    "    sleep_stage_annotations = wfdb.rdann(data_dir + file_name, 'st')\n",
    "\n",
    "    # Initial definitions\n",
    "    signal_names = fields['sig_name']\n",
    "    signals_to_keep = ['ECG', 'BP', 'EEG']\n",
    "    sampling_rate = 250\n",
    "    window_length_samples = 30 * sampling_rate\n",
    "\n",
    "    # Calculate the start index and the starting time\n",
    "    start_index = sleep_stage_annotations.sample[0]\n",
    "    time_start = start_index / sampling_rate\n",
    "    adjusted_start_index = int(time_start * sampling_rate)\n",
    "\n",
    "    # Filter and build the dictionary of selected signals\n",
    "    filtered_signals_dict = {\n",
    "        name: signals[:, i] if sleep_stage_annotations.sample[0] == 1 else signals[adjusted_start_index:, i]\n",
    "        for i, name in enumerate(signal_names) if any(sig in name for sig in signals_to_keep)\n",
    "    }\n",
    "\n",
    "    # Split the signals into windows of 7500 samples\n",
    "    windowed_signals_dict = {\n",
    "        name: signal[:(len(signal) // window_length_samples) * window_length_samples].reshape(-1, window_length_samples)\n",
    "        for name, signal in filtered_signals_dict.items()\n",
    "    }\n",
    "\n",
    "    # Extract labels for apneas\n",
    "    apnea_values = ['H', 'HA', 'OA', 'X', 'CA', 'CAA']\n",
    "    apnea_labels = [1 if any(marker in note for marker in apnea_values) else 0 for note in sleep_stage_annotations.aux_note]\n",
    "\n",
    "    # Build the final dictionary with the signals and associated labels\n",
    "    windows_with_labels = {\n",
    "        f\"{patient_id}_Window_{index}\": {**{name: signals[index] for name, signals in windowed_signals_dict.items()}, 'Label': apnea_labels[index]}\n",
    "        for index in range(min(len(next(iter(windowed_signals_dict.values()))), len(apnea_labels)))\n",
    "    }\n",
    "\n",
    "    return windows_with_labels\n",
    "\n",
    " ##################################################################################################################\n",
    "\n",
    "def prepare_data(windows_with_labels):\n",
    "    X_list = []\n",
    "    for window in windows_with_labels.values():\n",
    "        # Retrieve all values except the last one (which is the label)\n",
    "        signals = list(window.values())[:-1]\n",
    "        # Concatenate the signal arrays along a new axis to create a single numpy array for each window\n",
    "        concatenated_signals = np.concatenate([signal[np.newaxis, :] for signal in signals], axis=0)\n",
    "        X_list.append(concatenated_signals)\n",
    "\n",
    "    # Convert the list of numpy arrays into a single numpy array\n",
    "    X = np.array(X_list)\n",
    "\n",
    "    # 'X' now has shape (number_of_windows, number_of_signals, samples_per_window)\n",
    "    # Transpose 'X' to get the correct shape for LSTM model input: (number_of_windows, samples_per_window, number_of_signals)\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "\n",
    "    # Extract labels from the dictionary 'windows_with_labels'\n",
    "    y = np.array([window['Label'] for window in windows_with_labels.values()])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory and list of patients\n",
    "data_dir = r'C:\\Users\\feder\\Desktop\\Advanced Signal Modelling\\Project\\Data\\mit-bih-polysomnographic-database-1.0.0\\mit-bih-polysomnographic-database-1.0.0'\n",
    "patient_ids = ['slp04', 'slp66', 'slp16']\n",
    "\n",
    "\n",
    "# Global dictionary to hold data from all patients\n",
    "all_windows = {}\n",
    "\n",
    "# Process data for each patient and accumulate the results\n",
    "for patient_id in patient_ids:\n",
    "    patient_data = process_patient_data(patient_id, data_dir)\n",
    "    all_windows.update(patient_data)  # Add data from each patient to the global dictionary\n",
    "\n",
    "# Print a summary of the results\n",
    "print(f'Total windows processed from all patients: {len(all_windows)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the LSTM model\n",
    "X, y = prepare_data(all_windows)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "\n",
    "# Define the model with a compact structure including Dropout\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),  # Adds Dropout after the first LSTM\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),  # Adds Dropout after the second LSTM\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Uncomment the following line if learning rate reduction is needed\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Configuration for EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=20,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,  # Show messages\n",
    "    restore_best_weights=True  # Restore model weights from the best epoch\n",
    ")\n",
    "\n",
    "# Training the model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]  # Add the callback to the list of callbacks\n",
    ")\n",
    "\n",
    "# Model evaluation\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Model evaluation - Loss: {val_loss}, Accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting accuracy and loss data from the history object\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Creating the plot for accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo-', label='Training Acc')\n",
    "plt.plot(epochs, val_acc, 'r^-', label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Creating the plot for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r^-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the outputs using the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "# Rounding the predictions to the nearest integer\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "# Printing the classification report comparing actual and predicted values\n",
    "print(classification_report(y_test, y_pred, target_names=['No Apnea', 'Apnea']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a confusion matrix from the test labels and predicted labels\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Setting up the plot for the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Visualizing the confusion matrix as a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "# Labeling the x-axis as 'Predicted'\n",
    "plt.xlabel('Predicted')\n",
    "# Labeling the y-axis as 'True'\n",
    "plt.ylabel('True')\n",
    "# Setting the title of the plot as 'Confusion matrix'\n",
    "plt.title('Confusion matrix')\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model that takes inputs from an existing model and returns output from the second LSTM layer\n",
    "latent_model = Model(inputs=model.input, outputs=model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the latent representations from the test set\n",
    "latent_representations_test = latent_model.predict(X_test)\n",
    "\n",
    "# Apply t-SNE to the latent representations of test data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_embedded = tsne.fit_transform(latent_representations_test)\n",
    "\n",
    "# Visualize the results with matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_test, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE Visualization of Test Data Latent Representations')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the latent representations from the training set\n",
    "latent_representations_train = latent_model.predict(X_train)\n",
    "\n",
    "# Apply t-SNE to the latent representations of the training set\n",
    "tsne_train = TSNE(n_components=2, random_state=42)\n",
    "X_embedded_train = tsne_train.fit_transform(latent_representations_train)\n",
    "\n",
    "# Visualize the results with matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_embedded_train[:, 0], X_embedded_train[:, 1], c=y_train, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE Visualization of Training Set Latent Representations')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
